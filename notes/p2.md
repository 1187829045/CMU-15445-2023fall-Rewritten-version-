## Task1

Read/Write Page Guards

为了表示页面在内存中不再需要，程序员必须手动调用UnpinPage。如果程序员忘记调用UnpinPage，页面将永远不会从缓冲池中驱逐出去.将实现BasicPageGuard，它存储指向BufferPoolManager和Page对象的指针。页面保护确保在相应的Page对象超出范围时调用UnpinPage。注意，它仍应提供一种方法，让程序员可以手动取消页面固定。
由于BasicPageGuard隐藏了底层的Page指针，它还可以提供只读/写数据API，这些API提供编译时检查，以确保is_dirty标志为每个用例正确设置。
多个线程将读取和写入同一页面，因此需要读写锁来确保数据的正确性。注意，在Page类中，有相关的锁方法用于此目的。与取消页面固定类似，程序员在使用后可能会忘记解除页面锁定。为解决这个问题，你将实现ReadPageGuard和WritePageGuard，它们会在页面超出范围时自动解除页面锁定。

### BasicPageGuard(BasicPageGuard &&that) noexcept; 
实现移动构造函数，复制原本到新副本，并使原来的守卫对象不再可用

### void Drop();
释放一个页面守卫（page guard），并清空其所有内容，使其不再有用，通知 BPM（缓冲池管理器）我们已经完成了对该页面的使用。
如果当前BasicPageGuard保护的页面不为空且指向的bpm也不为空，那么调用bpm_的UnpinPage方法，然后设置当前BasicPageGuard，bpm,page为空,

### auto operator=(BasicPageGuard &&that) noexcept -> BasicPageGuard &;
BasicPageGuard 的移动赋值运算符,首先调用Drop释放原有资源，然后再赋值

### auto UpgradeRead() -> ReadPageGuard;
* 在升级过程中，被保护的页面不会从缓冲池中逐出，
* 并且在调用此函数后，基本页面守卫应变得无效。
UpgradeWrite()与之类似；

## Task2- 1.扩展哈希表页面
实现三个 Page 类来存储扩展哈希表的数据：

哈希表头页面（Hash Table Header Page）

哈希表目录页面（Hash Table Directory Page）

哈希表桶页面（Hash Table Bucket Page）

### 哈希表头页面（Hash Table Header Page）
头页面位于基于磁盘的扩展哈希表的第一层，并且哈希表只有一个头页面。它存储指向目录页面的逻辑子指针（作为页面 ID）。你可以将它视为静态的第一层目录页面。
头页面具有以下字段： directory_page_ids_，max_depth_，尽管页面的大小有物理限制，你应该使用 max_depth_ 来确定 directory_page_ids 数组大小的上限。

### void ExtendibleHTableHeaderPage::Init(uint32_t max_depth)
设置最大深度，和初始化目录Id数组初始化为无效ID

### auto ExtendibleHTableHeaderPage::HashToDirectoryIndex(uint32_t hash) const -> uint32_t
根据前max_depth位来hash ，比如101010前两位10向右移4位剩下10

### auto GetDirectoryPageId(uint32_t directory_idx) const -> uint32_t
获取指定索引处的目录页面 ID
this->directory_page_ids_[directory_idx];

###  void SetDirectoryPageId(uint32_t directory_idx, page_id_t directory_page_id);
设置指定索引处的目录页面 ID
directory_page_ids_[directory_idx] = directory_page_id;

## Hash Table Directory Page
目录页面位于我们基于磁盘的可扩展哈希表的第二层。每个目录页面存储了指向桶页面的逻辑子指针（作为页面 ID），以及用于处理桶映射和动态目录扩展与收缩的元数据。目录页面具有以下字段：

变量名称	-------------大小------------------- 描述

max_depth_------------4------------头页面可以处理的最大深度

global_depth_---------	       4----------------     	   当前目录的全局深度

local_depths_---------	      512-----------	       桶页面局部深度的数组

bucket_page_ids_-----      2048-----------	       桶页面 ID 的数组

注意，虽然页面的物理大小有限，但你应该使用 max_depth_ 来确定 bucket_page_ids_ 数组大小的上限。

###   void Init(uint32_t max_depth = HTABLE_DIRECTORY_MAX_DEPTH);
max_depth_ = max_depth;

global_depth_ = 0;

// 初始化目录页ID数组，将所有值设为无效ID
std::fill(local_depths_, local_depths_ + (1 << max_depth), 0);

std::fill(bucket_page_ids_, bucket_page_ids_ + (1 << max_depth), INVALID_PAGE_ID);

###   auto HashToBucketIndex(uint32_t hash) const -> uint32_t;
通过hash得到桶组的下标

### auto GetSplitImageIndex(uint32_t bucket_idx) const -> uint32_t;
分裂桶，比如本身以最后两位来映射到为哪个桶 比如最后两位01 分裂的话就是加倍桶的数量那么101和001以最后三位来映射

###  void IncrGlobalDepth()
增加全局深度，等于加倍桶的数量，初始化后一半桶，因为局部深度不变，所以应该指向相同的桶，比如全局深度是3，现在变成4那么bucket_page_ids_与local_depths_
应该加倍，但比如局部深度依旧是2，那么001和101依旧指向同一个桶。所以这样初始化， bucket_page_ids_[(1 << global_depth_) + i] = bucket_page_ids_[i];
local_depths_[(1 << global_depth_) + i] = local_depths_[i];

DecrGlobalDepth()这个直接--就可以
### CanShrink() 
判断该目录全局深度是否可以压缩，全局深度=0||有局部深度=全局深度返回false

### 哈希表桶页（Bucket Page）

### Lookup
查找key,如果找到了把key(array[i],first)对应的值(array[i].second)赋给value，返回true
循环遍历数组，再比较cmp(array_[i].first, key)

### Insert 
插入一个键值对,判断桶数组是不是已满，或者该键值对是否已存在，再插入

Remove类似，找到键删除，然后后面的往前面移动一格

EntryAt(uint32_t bucket_idx)	获取桶中指定索引处的键值对[key,value]

KeyAt(uint32_t bucket_idx)	获得bucket_idx对应的key

ValueAt(uint32_t bucket_idx)	获得bucket_idx对应的value

Size()	桶里有几个键值对

IsFull()	桶是否满了

IsEmpty()	桶是否为空


## Task3- 可扩展哈希实现
通过申请读写页的方式来管理增删改查、申请新页来管理分裂桶、删除空页合并桶。
实现需要支持插入、点查找和删除操作。可扩展哈希表的头文件和 cpp 文件中已经实现或记录了许多辅助函数。你的唯一严格的 API 要求是遵守 Insert、GetValue 和 Remove。你还必须保持 VerifyIntegrity 函数不变。
哈希表只支持唯一键。这意味着如果用户尝试插入重复键，哈希表应返回 false。你应该使用在任务 #2 中实现的页面类来存储键值对以及维护哈希表的元数据（页面 id，全局/局部深度）。例如，你不应该使用内存数据结构如 std::unordered_map 来模拟哈希表。

BufferPoolManager *bpm_	要使用的缓冲区池管理器

KC cmp_	键的比较器

HashFunction hash_fn_	哈希函数

header_max_depth_	头部页面允许的最大深度

directory_max_depth_	目录页面允许的最大深度

bucket_max_size_	桶页面允许的最大深度

header_page_id_	头目录pageid
### GetValue函数
加锁形式 ReadPageGuard header_guard = bpm_->FetchPageRead(header_page_id_);

得到header_page然后调用header_page的HashToDirectoryIndex函数获取directory_index，然后获取directory_page_id之后通过FetchPageRead函数获取
directory_guard再获取page,之后获取对应的 bucket_page，然后获取值加入result中。

### Insert

加写锁，WritePageGuard header_guard = bpm_->FetchPageWrite(header_page_id_);释放锁 header_guard.Drop();

插入值是否重复->header_page加读锁->获取directory_page_id ->解锁，目录页加锁-> bucket_page_id -> 对bucket加锁->bucket_page->Insert(key, value, cmp_)如果插入成功
直接返回true,否则就是说明桶满了，加深度，如果当前桶深度小于全局直接增加就好，如果等于全局深度，就要判断全局深度可不可以增加（是否小于最大深度）；
### UpdateDirectoryMapping	更新目录索引
遍历目录页，检查目录条目是否需要更新为指向新桶directory->GetBucketPageId(i) == directory->GetBucketPageId(new_bucket_idx)，如果目录项对应的是原桶，如果这个目录项的在新局部深度位上的值为1，应该指向新桶，否则，它仍然指向原桶，但其局部深度需要更新

### Remove-移除键值对
跟GetValue类似一步步遍历到桶，加写锁， bool remove_success = bucket_page->Remove(key, cmp_);调用这个方法移除该键值对
，判断该桶页是不是为空，为空就合并，

    //得到分裂的桶，准备重新合并

    auto merge_bucket_index = directory_page->GetSplitImageIndex(bucket_index);

    auto merge_bucket_local_depth = directory_page->GetLocalDepth(merge_bucket_index);

    auto merge_bucket_page_id = directory_page->GetBucketPageId(merge_bucket_index);

空桶和想要合并桶深度一样，减小局部深度合并在一起比如 011应该和111合并在一起所以是bucket_local_depth - 1，然后要更新所以以最后local_depth相同的桶下标

      uint32_t traverse_bucket_idx =
          std::min(bucket_index & directory_page->GetLocalDepthMask(bucket_index), merge_bucket_index);
      uint32_t distance = 1 << (bucket_local_depth -
                                1);  //减小局部深度合并在一起比如 011应该和111合并在一起所以是bucket_local_depth - 1
      uint32_t new_local_depth = bucket_local_depth - 1;
      for (uint32_t i = traverse_bucket_idx; i < directory_page->Size(); i += distance) {
        directory_page->SetBucketPageId(i, merge_bucket_page_id);
        directory_page->SetLocalDepth(i, new_local_depth);
      }
   //重新设置参数，然后删去已被合并的桶
`   auto split_image_bucket_index = directory_page->GetSplitImageIndex(merge_bucket_index);  // 11->01

   auto split_image_bucket_page_id = directory_page->GetBucketPageId(split_image_bucket_index);

   WritePageGuard split_image_bucket_guard = bpm_->FetchPageWrite(split_image_bucket_page_id);

   if (split_image_bucket_page_id == INVALID_PAGE_ID) {

   break;

   }
   auto helper = bucket_page_id;

   bucket_index = split_image_bucket_index;

   bucket_page_id = split_image_bucket_page_id;
   bucket_guard = std::move(split_image_bucket_guard);

   bucket_page = bucket_guard.AsMut<ExtendibleHTableBucketPage<K, V, KC>>();

   bpm_->DeletePage(helper);
 
 `
 

 
 
### SplitBucket-分裂桶（自己定义的）

创建新bucket_page

page_id_t split_page_id;

WritePageGuard split_bucket_guard = bpm_->NewPageGuarded(&split_page_id).UpgradeWrite();

if (split_page_id == INVALID_PAGE_ID) {

return false;

}

auto split_bucket = split_bucket_guard.AsMut<ExtendibleHTableBucketPage<K, V, KC>>();


获取split_idx，directory->GetSplitImageIndex(bucket_idx);
设置该下标对应刚才新建的桶页，以及桶的深度，
将原来满的bucket_page拆分到两个page页中
  page_id_t bucket_page_id = directory->GetBucketPageId(bucket_idx);
  if (bucket_page_id == INVALID_PAGE_ID) {
    return false;
  }
 // 先将原来的数据取出，放置在entries容器中
  int size = bucket->Size();
  std::list<std::pair<K, V>> entries;
  for (int i = 0; i < size; i++) {
    entries.emplace_back(bucket->EntryAt(i));
  }
  // 清空bucket:size_ = 0
  bucket->Clear();

  // 分到两个bucket_page中
`  for (const auto &entry : entries) {
    uint32_t target_idx = directory->HashToBucketIndex(Hash(entry.first));
    page_id_t target_page_id = directory->GetBucketPageId(target_idx);
    if (target_page_id == bucket_page_id) {
      bucket->Insert(entry.first, entry.second, cmp_);
    } else if (target_page_id == split_page_id) {
      split_bucket->Insert(entry.first, entry.second, cmp_);
    }
  }`
----------------------------------------------------
GrowShrinkTest：这个的缓冲池容量只有3，在 Insert 和 Remove 过程中，如果一个 PageGuard 已经不需要再使用了，
可以提前手动 Drop 而不是等离开作用域再进行析构。我的建议是只要得到了directory_id就把header的解开。directory
和bucket不急着解，运行不通过再加Drop();如果提交有：page4 not exist那就是drop早了，如果是：0000000000xread 
memory就是drop晚了。




Debug

/home/llb/CMU-15445-2023fall-Rewritten-version-/cmake-build-debug/test/extendible_htable_test --gtest_filter=ExtendibleHTableTest.InsertTest1:ExtendibleHTableTest/*.InsertTest1:ExtendibleHTableTest.InsertTest1/*:*/ExtendibleHTableTest.InsertTest1/*:*/ExtendibleHTableTest/*.InsertTest1 --gtest_color=no
Testing started at 10:52 AM ...
ASAN:DEADLYSIGNAL
Running main() from gmock_main.cc
Process finished with exit code 1
出现此错误可能的原因
以下是一些可能导致这种错误的原因：

非法指针访问：尝试访问已经释放或未初始化的指针。

缓冲区溢出：数组或缓冲区的访问超出了其分配的边界。

未对齐的内存访问：在某些平台上，访问未对齐的内存地址可能导致总线错误。

栈溢出：递归调用太深或分配过大的局部变量导致栈空间耗尽。

通过gdb调试显示
出错位置：bustub::Page::GetData 函数的第 43 行，这里函数尝试返回一个成员变量 data_ 的值。
指针值：this=0x0，表示调用该函数的对象指针是 nullptr（即空指针），因此当函数试图访问 data_ 时发生了错误，因为空指针没有指向有效的内存区域。
调用UpgradeWrite()时，  触发assert(page_== nullptr);
通过查找  WritePageGuard(BufferPoolManager *bpm, Page *page) : guard_(bpm, page) {}未正确初始化


